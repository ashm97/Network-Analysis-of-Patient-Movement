{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher-order analysis of path data in `pathpy`\n",
    "\n",
    "\n",
    "**June 12 2020**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathpy as pp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Temporal Network Represenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key idea is that the ordering and timing in which time-stamped edges occur in a `TemporalNetwork` gives rise to so-called **causal or time-respecting paths**. In a nutshell, for two time-stamped edges $(a, b, t)$ and $(b, c, t')$ to contribute to a causal path $a \\rightarrow b \\rightarrow c$ it must hold that $t < t'$. If we swap timestamps such that the edge $(b, c)$ occurs **before** (a,b), no causal path $a \\rightarrow b \\rightarrow c$ exists.\n",
    "\n",
    "So we observe that the chronological order of time-stamped edges crucially influences causal paths, i.e. which nodes can possibly influence each other in time-stamped edge sequences. Moreover, we often want to limit the **maximum time difference between consecutive edges** that contribute to a causal path. For data on dynamic social interactions that spans several years, it does not make sense to consider all chronologically ordered edges as possible causal paths for the propagation of information. After all, humans have limited memory and we should thus consider interactions that occur far apart in time as independent.\n",
    "\n",
    "We can formally add this condition by setting a maximum time difference $\\delta$ for the path calculation. That is, we only consider two edges $(a, b, t)$ and $(b, c, t')$ to contribute to a causal path $a \\rightarrow b \\rightarrow c$ if $ 0 < t' - t \\leq \\delta$.\n",
    "\n",
    "With this definition at hand, and by setting our maximum time difference $\\delta$, we can now **calculate causal path statistics in time-stamped network data**. `pathpy` provides powerful algorithms to calculate (or estimate) causal path statistics based on a `TemporalNetwork` instance. Let us try this in our toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv('./Patient Data/CPE_temporal_edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pp.TemporalNetwork()\n",
    "\n",
    "for index, row in patients.iterrows():\n",
    "    t.add_edge(row[0], row[1], row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "style = {    \n",
    "  'ts_per_frame': 7, \n",
    "  'ms_per_frame': 150,\n",
    "  'look_ahead': 200, \n",
    "  'look_behind': 200, \n",
    "  'node_size': 8, \n",
    "  'inactive_edge_width': 2,\n",
    "  'active_edge_width': 4, \n",
    "  'label_color' : 'black',\n",
    "  'label_size' : '5px',\n",
    "  'label_offset': [0,0], \n",
    "    'width': 800, 'height': 500\n",
    "  }\n",
    "\n",
    "pp.visualisation.plot(t, **style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.visualisation.export_html(t, 'CPE_temporal_network.html', **style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "causal_paths = pp.path_extraction.temporal_paths.paths_from_temporal_network_dag(t, delta=7)\n",
    "print(causal_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in causal_paths.paths:\n",
    "    for p in causal_paths.paths[l]:\n",
    "        if causal_paths.paths[l][p][1]>0:\n",
    "            print('{0} -> {1}'.format(p, causal_paths.paths[l][p][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Higher order Models from actual pathway data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data analysis and modelling framework outlined in these works builds on a generalisation of standard, first-order networks to $k$-dimensional De Bruijn graph models for paths in complex networks.\n",
    "\n",
    "Note: De Bruijn graph of $m$ symbols is a directed graph representing overlaps between sequences of symbols. \n",
    "\n",
    "The class `HigherOrderNetwork` allows us to generate such higher-order network models of paths. In the documentation, we find that the constructor takes a parameter `paths`, i.e. the statistics of the observed paths that we want to model. With the parameter `k` we specify the order $k$ of the higher-order model that we want to fit. To understand this better, let us do this for our toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = pd.read_csv('./Patient Data/CPE_pathways.csv') \n",
    "\n",
    "patientPaths = pp.Paths()\n",
    "\n",
    "for index, row in paths.iterrows():\n",
    "    patientPaths.add_path(row[0],  separator='-', frequency=1)\n",
    "\n",
    "#patientPaths *= 8\n",
    "\n",
    "#patientPaths = causal_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output confirms that a `HigherOrderModel` with $k=1$ is identical to our `Network` model. WIth one exception: edge weights are vector-valued. Just like in `Paths`, the first entry captures the sub-path frequency while the second entry counts the occurrence of an edge as a longest path. \n",
    "\n",
    "We can see this network as a **first-order model** for paths where **edges are paths of length one**. That is, in a model with order $k=1$ edge weights capture the statistics of paths of length $k=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hon_1 = pp.HigherOrderNetwork(patientPaths, k=1)\n",
    "print(hon_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "style = { 'label_offset': [0,-1], 'label_color' : 'black', 'width': 800, 'height': 500,'label_size' : '5px'}\n",
    "pp.visualisation.plot(hon_1, **style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generalise this idea to **k-th-order models** for paths, where **nodes are paths of length $k-1$** while **edge weights capture the statistics of paths of length $k$**. We can generate such a $k$-th order model by performing a line graph transformation on a model with order $k-1$. That is, edges in the model of order $k-1$ become nodes in the model with order $k$. We then draw edges between higher-order nodes whenever there is a possible path of length $k$ in the underlying network. The result is a $k$-dimensional De Bruijn graph model for paths. Let us try this in our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hon_2 = pp.HigherOrderNetwork(patientPaths, k=2)\n",
    "#pp.visualisation.plot(hon_2, **style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the **edges** in the first-order model is now represented by a **node** in the second-order model.\n",
    "\n",
    "This is important because it captures to what extent the paths that we observe in our data deviate from what we would expect based on the (first-order) network topology of the system. Considering such a first-order model, all paths of length two are possible. If edges were statistically independent we would expect all paths f length 2 to occur with the same frequency.\n",
    "\n",
    "Another way to express this independence assumption is to consider Markov chain models for the sequences of nodes traversed by a path. In this view, independently occurring edges translate to a memoryless first-order Markov process for the node sequence. \n",
    "\n",
    "`pathpy` can actually generate this **null-model** for paths within the space of possible second-order models. This allows us to  compare how the observed path statistics deviate from a (Markovian) expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hon_2_null = pp.HigherOrderNetwork(patientPaths, k=2, null_model=True)\n",
    "#pp.visualisation.plot(hon_2_null, **style)\n",
    "\n",
    "#for e in hon_2_null.edges:\n",
    "#    print(e, hon_2_null.edges[e])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily find out which of the paths of length two occur more or less often than expected under the null model. We can just subtract the adjacency matrices of the two instances `hon_2` and `hon_2_null`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A_2 = hon_2.adjacency_matrix()\n",
    "idx_2 = hon_2.node_to_name_map()\n",
    "\n",
    "A_2n = hon_2_null.adjacency_matrix()\n",
    "idx_2n = hon_2_null.node_to_name_map()\n",
    "\n",
    "#for (v,w) in hon_2_null.edges:\n",
    "#    print(e, A_2[idx_2[v],idx_2[w]] - A_2n[idx_2n[v],idx_2n[w]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis confirms that the paths a number of paths occur more times than we would expect at random, while the other paths do occur less times than expected. Importantly, this deviation from our expectation changes the causal topology of the system, i.e. who can influence whom. In a network model we implicitly assume that paths are transitive, i.e. since $a$ is connected to $c$ and $c$ is connected to $d$ we assume that there is a path by which $a$ can influence $d$ via node $c$. The second-order model of our data reveals that this transitivity assumption is misleading, highlighting higher-order dependencies in our data that result in the fact that neither some $a$ can influence some $d$ nor some $b$ can always influence some $e$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking nodes in higher-order networks\n",
    "\n",
    "In summary, higher-order models capture deviations from the transitivity assumption that we often implicitly make when we apply standard graph mining or network analysis techniques. An important class of methods that rely on this assumption are centrality measures, which are often used to rank nodes in networked systems.\n",
    "\n",
    "Let us consider the betweenness value of a node $v$, which (in its unnormalized variant) captures for how many pairs of nodes $x,y$ the shortest path from $x$ to $y$ passes through $v$. This measure is important, because is teaches us something about the role of nodes in information flow. It further captures to what extent removing a node will affect the shortest paths between other nodes. Let us try this in our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pp.algorithms.centralities.betweenness(hon_1)['SM_ZCO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this notion of *importance* of node $c$ is based on the assumption that paths are transitive and Markovian, which is not the case in our observed paths. `pathpy` actually allows us to calculate the betweenness of node $c$ in the observed paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pp.algorithms.centralities.betweenness(patientPaths)['SM_ZCO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, the betweenness of the node in the actual paths is different. This change in centrality can be captured in the higher-order model and `pathpy` allows us to directly generalize centrality measures to higher orders, simply by calling the functions on the class `HigherOrderNetwork`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pp.algorithms.centralities.betweenness(hon_2)['SM_ZCO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pp.algorithms.centralities.betweenness(hon_2_null)['SM_ZCO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageRank_hon1 = pp.algorithms.centralities.pagerank(hon_1)\n",
    "pageRank_hon2 = pp.algorithms.centralities.pagerank(hon_2)\n",
    "pageRank_hon2_null = pp.algorithms.centralities.pagerank(hon_2_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting node rankings with higher-order models\n",
    "\n",
    "Let us now explore how we can apply higher-order models in practical prediction tasks. Assume we are given the task to rank nodes in a network according to how often they are traversed by paths. This has practical applications, e.g. predicting the most frequently clicked Web pages based on the topology of the link graph, or predicting the most congested airports based on the topology of flight connections. Let us study the latter example based on a data set on the paths of airline passengers in the United Stated.\n",
    "\n",
    "For your convenience, we have partitioned the data set into a training and a validation set of equal size. Our goal will be to use the training set to learn (higher-order) network models. We then calculate a higher-order generalisation of `pagerank` described [in this paper](http://dl.acm.org/citation.cfm?id=3098145) in these models to predict the ranking of airports according to the number of passengers in the validation set.\n",
    "\n",
    "<span style=\"color:red\">**TODO:** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Paths into test and train\n",
    "#paths = pd.read_csv('./Patient Data/CPE_pathways_more2moves.csv') \n",
    "paths = pd.read_csv('./Patient Data/CPE_pathways.csv') \n",
    "msk = np.random.rand(len(paths)) < 0.6\n",
    "train, test = paths[msk], paths[~msk]\n",
    "trainPaths = pp.Paths()\n",
    "testPaths = pp.Paths()\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    trainPaths.add_path(row[0],  separator='-', frequency=1)\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    testPaths.add_path(row[0],  separator='-', frequency=1)\n",
    "    \n",
    "#gt = pp.algorithms.centralities.pagerank(pp.HigherOrderNetwork(testPaths, k=2))\n",
    "gt = pp.algorithms.centralities.node_traversals(testPaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to evaluate the goodness of this prediction (in terms of the node ranking) using the Kendall-Tau rank correlation coefficient. Since the overlap between the nodes observed in the training data, and the nodes observed in the validation data may not be perfect, we first need a function that calculates the Kendall-Tau correlation for the intersection of nodes in the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendalltau(a, b):\n",
    "    x = []\n",
    "    y = []\n",
    "    for v in set(a.keys()).intersection(set(b.keys())):\n",
    "            x.append(a[v])\n",
    "            y.append(b[v])\n",
    "    return scipy.stats.kendalltau(x, y)\n",
    "\n",
    "\n",
    "def validate(mog, gt):\n",
    "    res = {}\n",
    "    for k in range(1, mog.max_order+1):\n",
    "        pr = pp.algorithms.centralities.pagerank(mog.layers[k])\n",
    "        res[k] = kendalltau(gt, pr).correlation\n",
    "    return res\n",
    "\n",
    "def plot_results(res, optimal_order):\n",
    "    if optimal_order>1:\n",
    "        diff = res[optimal_order] - res[1]\n",
    "        print('Relative increase over first-order = {0} %'.format(100*diff/res[1]))\n",
    "    plt.plot(range(1, max(res.keys())+1), [res[k] for k in range(1, max(res.keys())+1)], '-o')\n",
    "    #plt.plot([optimal_order], [res[optimal_order]], 'g', marker='x', markersize=20.0)\n",
    "    plt.title('Kendall-Tau')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mog = pp.MultiOrderModel(trainPaths, 6)\n",
    "order = mog.estimate_order()\n",
    "\n",
    "res = validate(mog, gt)\n",
    "plot_results(res, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for x in range(6):\n",
    "    msk = np.random.rand(len(paths)) < 0.6\n",
    "    train, test = paths[msk], paths[~msk]\n",
    "    trainPaths = pp.Paths()\n",
    "    testPaths = pp.Paths()\n",
    "\n",
    "    for index, row in train.iterrows():\n",
    "        trainPaths.add_path(row[0],  separator='-', frequency=1)\n",
    "\n",
    "    for index, row in test.iterrows():\n",
    "        testPaths.add_path(row[0],  separator='-', frequency=1)\n",
    "    \n",
    "    gt = pp.algorithms.centralities.node_traversals(testPaths)\n",
    "    \n",
    "    l_mog = pp.MultiOrderModel(trainPaths, 6)\n",
    "    l_order = mog.estimate_order()\n",
    "\n",
    "    l_res = validate(mog, gt)\n",
    "    \n",
    "    res.append(l_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(1, max(res[0].keys())+1), [res[0][k] for k in range(1, max(res[0].keys())+1)], '-o')\n",
    "plt.plot(range(1, max(res[1].keys())+1), [res[1][k] for k in range(1, max(res[1].keys())+1)], '-o')\n",
    "plt.plot(range(1, max(res[2].keys())+1), [res[2][k] for k in range(1, max(res[2].keys())+1)], '-o')\n",
    "plt.plot(range(1, max(res[3].keys())+1), [res[3][k] for k in range(1, max(res[3].keys())+1)], '-o')\n",
    "plt.plot(range(1, max(res[4].keys())+1), [res[4][k] for k in range(1, max(res[4].keys())+1)], '-o')\n",
    "plt.plot(range(1, max(res[5].keys())+1), [res[5][k] for k in range(1, max(res[5].keys())+1)], '-o')\n",
    "\n",
    "plt.legend(['Boot0','Boot1', 'Boot2', 'Boot3', 'Boot4','Boot5'], loc='upper left')\n",
    "\n",
    "plt.title('Kendall-Tau Rank Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mog = pp.MultiOrderModel(trainPaths, 6)\n",
    "order = mog.estimate_order()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Multi-order Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = pd.read_csv('./Patient Data/CPE_pathways.csv') \n",
    "\n",
    "patientPaths = pp.Paths()\n",
    "\n",
    "for index, row in paths.iterrows():\n",
    "    patientPaths.add_path(row[0],  separator='-', frequency=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-order Representation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have studied higher-order network models for path data with a fixed, given order $k$. We have seen that such higher-order models can yield better predictions compared to standard network models. But we have also come across some open questions. For the US Flight data, we have seen that we could improve the prediction performance by moving from a first- to a second-order model. However, we did not see a further improvement for the third-order model. So in practice, how can we decide **at which order we should model a given system**? In fact, this points to a more general question. It is easy to imagine systems for which path statistics do not deviate significantly from the transitive, Markovian assumption made by a first-order network model. So we **need a methods to decide when higher-order models are actually needed**.\n",
    "\n",
    "Moreover, a higher-order model with order $k$ can only capture higher-order dependencies at a single fixed correlation length $k$. But we may encounter data that exhibit multiple correlation lengths at once. This raises the question how we  can combine models with multiple higher orders into a multi-order model.\n",
    "\n",
    "In this session, we take a statistical inference and machine learning perspective to answer these questions. Let us again start with a simple toy example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us take a statistical inference perspective on the problem. More specifically, we will consider our higher-order networks as probabilistic generative models for paths in a given network topology. For this, let us use the weighted first-order network model to construct a transition matrix of a Markov chain model for paths in a network. We simply use the relative frequencies of edges to proportionally scale the probabilities of edge transitions in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transition matrix can be viewed as a first-order Markov chain model for paths in the underlying network topology. This probabilistic view allows us to calculate a likelihood of the first-order model, given the paths that we have observed. With pathpy, we can directly calculate the likelihood of higher-order models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hon_2.likelihood(patientPaths, log=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hon_2_null = pp.HigherOrderNetwork(patientPaths, k=2, null_model=True)\n",
    "#pp.visualisation.plot(hon_2_null)\n",
    "#print(hon_2.transition_matrix())\n",
    "hon_2_null.likelihood(patientPaths, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection for higher-order network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection for higher-order network models\n",
    "\n",
    "This confirms our expectation that the second-order null model actually has the same likelihood as the first-order model. It also highlights an interesting way to test hypotheses about higher-order correlations in paths. We can use a likelihood ratio test to compare the likelihood of the null hypothesis (i.e. a second-order representation of the first-order model) with the likelihood of an alternative hypothesis (the *fitted* second-order model).\n",
    "\n",
    "But what do we learn from th fact that the likelihood of a model increases as we increase the order of the model. By itself, not much. The reason for this is that higher-order models are typicall more complex than first-order models, i.e. while fitting their transition matrix, we actually fit more parameters to the data. We can thus expect that they better explain our observations. \n",
    "\n",
    "We should remind ourselves about Occam's razor, which states that we should favor models that make fewer assumptions. That is, in the comparison of the model likelihoods we should account for the additional complexity (or degrees of freedom) of a higher-order model over the null hypothesis.\n",
    "\n",
    "A nice feature of our framework is that the null model and the alternative model are actually **nested**, i.e. the null model is one particular point in the parameter space of the (more general) higher-order model. Thanks to this property, we can apply [Wilk's theorem](https://en.wikipedia.org/wiki/Likelihood-ratio_test#Distribution:_Wilksâ€™_theorem) to derive an analytical expression for the $p$-value of the null hypothesis that second-order correlations are absent (i.e. that a first-order model is sufficient to explain the observed paths), compared to the alternative hypothesis that a second-order model is needed. You can find the mathematical details of this hypothesis testing technique in the following KDD'17 paper:\n",
    "\n",
    "I Scholtes: [When is a Network a Network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks](http://dl.acm.org/citation.cfm?id=3098145), In KDD'17 - Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, Nova Scotia, Canada, August 13-17, 2017\n",
    "\n",
    "Let us now apply this likelihood ratio test the hypothesis that there are significant second-order dependencies in the paths of our toy example. The test consists of three basic steps: \n",
    "\n",
    "1. We calculate the difference $d$ between the degrees of freedom of a second- and a first-order model.\n",
    "2. We calculate the test statistic $x = -2 \\cdot(\\log(\\text{hon_1.likelihood}) - \\log(\\text{hon_2.likelihood}))$ for the likelihood ratio test.\n",
    "3. We calculate a p-value as $1-cdf(x, d)$, where $cdf$ is the cumulative distribution function of a chi-square distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "d = hon_2.degrees_of_freedom() - hon_1.degrees_of_freedom()\n",
    "x = - 2 * (hon_1.likelihood(patientPaths, log=True) - hon_2.likelihood(patientPaths, log=True))\n",
    "p = 1 - chi2.cdf(x, d)\n",
    "\n",
    "print('The p-value of the null hypothesis (first-order model) is {0}'.format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-order representation learning\n",
    "\n",
    "To fix this issue, we need probabilistic generative models that can deal with large collections of (short) paths in a network. The key idea is to combine multiple higher-order network models into a single multi-layered, multi-order model. To calculate the likelihood of such a model based on a set of observed paths, we can use all layers, thus avoiding the problem that we discard prefixes of paths. For each path, we start at a layer of order zero, which considers the relative probabilities of nodes. We use this model layer to calculate the probability to observe the first node on a path. For the next transition to step two, we then use a first-order model. The next transition is calculated in the second-order model and so on, until we have reached the maximum order of our multi-order model. At this point, we can transitively calculate the likelihood based on the remaining transitions of the path.\n",
    "\n",
    "The method is described, and illustrated with an example, in the following paper:\n",
    "\n",
    "I Scholtes: [When is a Network a Network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks](http://dl.acm.org/citation.cfm?id=3098145), In KDD'17 - Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, Nova Scotia, Canada, August 13-17, 2017\n",
    "\n",
    "`pathpy` can directly generate, visualise, and analyse multi-order network models. Let us try this in our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mog = pp.MultiOrderModel(patientPaths, max_order=3)\n",
    "print(mog)\n",
    "\n",
    "#pp.visualisation.plot(mog.layers[0])\n",
    "#pp.visualisation.plot(mog.layers[1])\n",
    "#pp.visualisation.plot(mog.layers[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now use the likelihood function of the class MultiOrderModel to repeat our likelihood ratio test. Rather than generating multiple MultiOrderModel instances for different hypotheses, we can directly calculate likelihoods based on different model layers within the same MultiOrderModel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mog = pp.MultiOrderModel(patientPaths, max_order=3)\n",
    "\n",
    "d = mog.degrees_of_freedom(max_order=2) - mog.degrees_of_freedom(max_order=1)\n",
    "x = - 2 * (mog.likelihood(patientPaths, log=True, max_order=1) - mog.likelihood(patientPaths, log=True, max_order=3))\n",
    "p = 1 - chi2.cdf(x, d)\n",
    "\n",
    "print('p value of null hypothesis that data has maximum order 1 = {0}'.format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than performing the likelihood test ourselves, we can actually simply call the method `MultiOrderModel.estimate_order`. it will return the maximum order among all of its layers for which the likelihood ratio test rejects the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mog.estimate_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
